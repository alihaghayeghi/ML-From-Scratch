{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KNN from Scratch (NumPy-only core) + Mammographic Mass (UCI) Example\n",
        "\n",
        "This notebook builds **K-Nearest Neighbors** end-to-end **without using scikit-learn or any existing KNN model**.\n",
        "The core algorithm uses **only NumPy**.\n",
        "\n",
        "We then add features that are typically not exposed in `sklearn`'s KNN API:\n",
        "- native **missing-value-aware distances**\n",
        "- **mixed-type feature handling** (ordinal/nominal)\n",
        "- **learned diagonal Mahalanobis metric** (simple metric learning)\n",
        "- ability to **return neighbors** and produce a basic **local explanation**\n",
        "- simple **set-valued prediction** for uncertainty\n",
        "\n",
        "Dataset page: https://archive.ics.uci.edu/dataset/161/mammographic+mass  \n",
        "UCI notes this dataset has **961 instances**, **5 features**, and **missing values**. \ue200cite\ue202turn3view0\ue201\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(42)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Download + parse the UCI Mammographic Mass dataset\n",
        "\n",
        "Raw columns (6):\n",
        "1. BI-RADS (1..5)\n",
        "2. Age\n",
        "3. Shape (1..4)\n",
        "4. Margin (1..5)\n",
        "5. Density (1..4)\n",
        "6. Severity (target): benign=0, malignant=1\n",
        "\n",
        "UCI reports missing values in several attributes. \ue200cite\ue202turn3view0\ue201\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mammographic-masses/mammographic_masses.data\"\n",
        "local_path = Path(\"mammographic_masses.data\")\n",
        "\n",
        "if not local_path.exists():\n",
        "    urllib.request.urlretrieve(DATA_URL, local_path.as_posix())\n",
        "\n",
        "raw = local_path.read_text().strip().splitlines()\n",
        "raw[:5], len(raw)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def parse_mammographic_mass(lines):\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "    for line in lines:\n",
        "        parts = [p.strip() for p in line.split(\",\")]\n",
        "        if len(parts) != 6:\n",
        "            continue\n",
        "        *feat, target = parts\n",
        "        row = []\n",
        "        for v in feat:\n",
        "            row.append(np.nan if v == \"?\" else float(v))\n",
        "        if target == \"?\":\n",
        "            continue\n",
        "        X_list.append(row)\n",
        "        y_list.append(int(float(target)))\n",
        "    return np.array(X_list, dtype=float), np.array(y_list, dtype=int)\n",
        "\n",
        "X_raw, y = parse_mammographic_mass(raw)\n",
        "X_raw.shape, y.shape, np.mean(np.isnan(X_raw), axis=0)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Preprocessing (NumPy)\n",
        "\n",
        "- train/test split (stratified)\n",
        "- median imputation\n",
        "- standardization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def train_test_split_np(X, y, test_size=0.2, seed=42, stratify=True):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    n = X.shape[0]\n",
        "    idx = np.arange(n)\n",
        "\n",
        "    if stratify:\n",
        "        idx0 = idx[y == 0]\n",
        "        idx1 = idx[y == 1]\n",
        "        rng.shuffle(idx0); rng.shuffle(idx1)\n",
        "        n_test0 = int(round(len(idx0) * test_size))\n",
        "        n_test1 = int(round(len(idx1) * test_size))\n",
        "        test_idx = np.concatenate([idx0[:n_test0], idx1[:n_test1]])\n",
        "        train_idx = np.setdiff1d(idx, test_idx, assume_unique=False)\n",
        "        rng.shuffle(train_idx); rng.shuffle(test_idx)\n",
        "    else:\n",
        "        rng.shuffle(idx)\n",
        "        n_test = int(round(n * test_size))\n",
        "        test_idx = idx[:n_test]\n",
        "        train_idx = idx[n_test:]\n",
        "\n",
        "    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
        "\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split_np(X_raw, y, test_size=0.2, seed=42, stratify=True)\n",
        "X_train_raw.shape, X_test_raw.shape, np.bincount(y_train), np.bincount(y_test)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def nanmedian_impute_fit(X):\n",
        "    return np.nanmedian(X, axis=0)\n",
        "\n",
        "def nanmedian_impute_transform(X, med):\n",
        "    X2 = X.copy()\n",
        "    for j in range(X.shape[1]):\n",
        "        m = np.isnan(X2[:, j])\n",
        "        X2[m, j] = med[j]\n",
        "    return X2\n",
        "\n",
        "def standardize_fit(X):\n",
        "    mu = np.mean(X, axis=0)\n",
        "    sigma = np.std(X, axis=0)\n",
        "    sigma = np.where(sigma == 0, 1.0, sigma)\n",
        "    return mu, sigma\n",
        "\n",
        "def standardize_transform(X, mu, sigma):\n",
        "    return (X - mu) / sigma\n",
        "\n",
        "med = nanmedian_impute_fit(X_train_raw)\n",
        "X_train_imp = nanmedian_impute_transform(X_train_raw, med)\n",
        "X_test_imp  = nanmedian_impute_transform(X_test_raw,  med)\n",
        "\n",
        "mu, sigma = standardize_fit(X_train_imp)\n",
        "X_train = standardize_transform(X_train_imp, mu, sigma)\n",
        "X_test  = standardize_transform(X_test_imp,  mu, sigma)\n",
        "\n",
        "X_train[:3]\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) KNN from scratch (NumPy-only core)\n",
        "\n",
        "This class supports classification and regression, distance/gaussian weighting,\n",
        "missing-aware distances, nominal features, diagonal metric learning, and explanations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class KNN:\n",
        "    '''\n",
        "    NumPy-only KNN supporting classification + regression, with extras:\n",
        "      - missing-aware distances\n",
        "      - mixed-type nominal/ordinal treatment\n",
        "      - diagonal metric learning (optional)\n",
        "      - return neighbors + per-feature explanation\n",
        "    '''\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        k=5,\n",
        "        task=\"classification\",\n",
        "        p=2.0,\n",
        "        metric=\"minkowski\",\n",
        "        weights=\"uniform\",\n",
        "        distance_power=1.0,\n",
        "        gaussian_sigma=1.0,\n",
        "        eps=1e-12,\n",
        "        nominal_idx=None,\n",
        "        missing=\"ignore\",\n",
        "        learn_diagonal_metric=False,\n",
        "        metric_strength=1.0\n",
        "    ):\n",
        "        self.k = int(k)\n",
        "        self.task = task\n",
        "        self.p = float(p)\n",
        "        self.metric = metric\n",
        "        self.weights = weights\n",
        "        self.distance_power = float(distance_power)\n",
        "        self.gaussian_sigma = float(gaussian_sigma)\n",
        "        self.eps = float(eps)\n",
        "        self.nominal_idx = set([] if nominal_idx is None else list(nominal_idx))\n",
        "        self.missing = missing\n",
        "        self.learn_diagonal_metric = bool(learn_diagonal_metric)\n",
        "        self.metric_strength = float(metric_strength)\n",
        "\n",
        "        self.X_ = None\n",
        "        self.y_ = None\n",
        "        self.diag_W_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        y = np.asarray(y)\n",
        "\n",
        "        if X.ndim != 2:\n",
        "            raise ValueError(\"X must be 2D\")\n",
        "        if X.shape[0] != y.shape[0]:\n",
        "            raise ValueError(\"X and y must have same number of rows\")\n",
        "        if self.k <= 0 or self.k > X.shape[0]:\n",
        "            raise ValueError(\"k must be in [1, n_train]\")\n",
        "\n",
        "        self.X_ = X\n",
        "        self.y_ = y\n",
        "\n",
        "        self.diag_W_ = self._learn_diagonal_weights(X, y) if self.learn_diagonal_metric else np.ones(X.shape[1])\n",
        "        return self\n",
        "\n",
        "    def _learn_diagonal_weights(self, X, y):\n",
        "        d = X.shape[1]\n",
        "        eps = self.eps\n",
        "        if self.task == \"classification\":\n",
        "            classes = np.unique(y)\n",
        "            if classes.size == 2:\n",
        "                X0 = X[y == classes[0]]\n",
        "                X1 = X[y == classes[1]]\n",
        "                mu0 = np.nanmean(X0, axis=0); mu1 = np.nanmean(X1, axis=0)\n",
        "                s0 = np.nanstd(X0, axis=0);  s1 = np.nanstd(X1, axis=0)\n",
        "                pooled = np.sqrt((s0**2 + s1**2) / 2.0) + eps\n",
        "                effect = np.abs(mu1 - mu0) / pooled\n",
        "                w = (effect + eps) ** self.metric_strength\n",
        "            else:\n",
        "                scores = np.zeros(d, dtype=float)\n",
        "                for c in classes:\n",
        "                    scores += self._learn_diagonal_weights(X, (y == c).astype(int))\n",
        "                w = scores / max(classes.size, 1)\n",
        "        else:\n",
        "            y2 = y.astype(float)\n",
        "            y2 = (y2 - np.mean(y2)) / (np.std(y2) + eps)\n",
        "            scores = np.zeros(d, dtype=float)\n",
        "            for j in range(d):\n",
        "                xj = X[:, j]\n",
        "                m = ~np.isnan(xj)\n",
        "                if np.sum(m) < 3:\n",
        "                    scores[j] = 0.0\n",
        "                    continue\n",
        "                xj2 = (xj[m] - np.mean(xj[m])) / (np.std(xj[m]) + eps)\n",
        "                scores[j] = np.abs(np.mean(xj2 * y2[m]))\n",
        "            w = (scores + eps) ** self.metric_strength\n",
        "\n",
        "        w = w / (np.mean(w) + eps)\n",
        "        return w\n",
        "\n",
        "    def _pairwise_distances(self, X_query):\n",
        "        Xq = np.asarray(X_query, dtype=float)\n",
        "        Xt = self.X_\n",
        "        if Xq.ndim == 1:\n",
        "            Xq = Xq[None, :]\n",
        "        n_q, d = Xq.shape\n",
        "        n_t = Xt.shape[0]\n",
        "        if d != Xt.shape[1]:\n",
        "            raise ValueError(\"dimension mismatch\")\n",
        "\n",
        "        sqrtW = np.sqrt(self.diag_W_)[None, :]\n",
        "        XqW = Xq * sqrtW\n",
        "        XtW = Xt * sqrtW\n",
        "\n",
        "        if self.metric == \"cosine\":\n",
        "            if self.missing == \"ignore\":\n",
        "                raise ValueError(\"cosine with missing='ignore' not supported; impute first\")\n",
        "            Xq2 = np.nan_to_num(XqW, nan=0.0)\n",
        "            Xt2 = np.nan_to_num(XtW, nan=0.0)\n",
        "            qn = np.linalg.norm(Xq2, axis=1, keepdims=True) + self.eps\n",
        "            tn = np.linalg.norm(Xt2, axis=1, keepdims=True) + self.eps\n",
        "            sim = (Xq2 @ Xt2.T) / (qn @ tn.T)\n",
        "            return 1.0 - sim\n",
        "\n",
        "        D = np.empty((n_q, n_t), dtype=float)\n",
        "        for i in range(n_q):\n",
        "            qi = XqW[i]\n",
        "            diff = XtW - qi[None, :]\n",
        "\n",
        "            if self.missing == \"ignore\":\n",
        "                mask = ~np.isnan(diff)\n",
        "                if self.nominal_idx:\n",
        "                    for j in self.nominal_idx:\n",
        "                        mj = mask[:, j]\n",
        "                        if np.any(mj):\n",
        "                            a = self.X_[:, j][mj]\n",
        "                            b = Xq[i, j]\n",
        "                            diff[mj, j] = (a != b).astype(float) * sqrtW[0, j]\n",
        "                present = np.sum(mask, axis=1)\n",
        "                ad = np.abs(np.where(mask, diff, 0.0))\n",
        "                dist_p = np.sum(ad ** self.p, axis=1)\n",
        "                dist = dist_p ** (1.0 / self.p)\n",
        "                D[i] = np.where(present > 0, dist, np.inf)\n",
        "            else:\n",
        "                diff2 = np.nan_to_num(diff, nan=0.0)\n",
        "                if self.nominal_idx:\n",
        "                    for j in self.nominal_idx:\n",
        "                        a = self.X_[:, j]\n",
        "                        b = Xq[i, j]\n",
        "                        diff2[:, j] = (a != b).astype(float) * sqrtW[0, j]\n",
        "                ad = np.abs(diff2)\n",
        "                D[i] = (np.sum(ad ** self.p, axis=1) + self.eps) ** (1.0 / self.p)\n",
        "\n",
        "        return D\n",
        "\n",
        "    def _neighbor_indices_and_distances(self, X_query):\n",
        "        D = self._pairwise_distances(X_query)\n",
        "        k = self.k\n",
        "        idx = np.argpartition(D, kth=k-1, axis=1)[:, :k]\n",
        "        row = np.arange(D.shape[0])[:, None]\n",
        "        dist_k = D[row, idx]\n",
        "        order = np.argsort(dist_k, axis=1)\n",
        "        idx_sorted = idx[row, order]\n",
        "        dist_sorted = dist_k[row, order]\n",
        "        return idx_sorted, dist_sorted\n",
        "\n",
        "    def _weights_from_distances(self, dist):\n",
        "        if self.weights == \"uniform\":\n",
        "            return np.ones_like(dist)\n",
        "        if self.weights == \"distance\":\n",
        "            return 1.0 / ((dist + self.eps) ** self.distance_power)\n",
        "        if self.weights == \"gaussian\":\n",
        "            s2 = (self.gaussian_sigma ** 2) + self.eps\n",
        "            return np.exp(-(dist ** 2) / (2.0 * s2))\n",
        "        raise ValueError(\"unknown weights\")\n",
        "\n",
        "    def predict(self, X_query, return_neighbors=False, return_proba=False, explain=False):\n",
        "        idx, dist = self._neighbor_indices_and_distances(X_query)\n",
        "        neigh_y = self.y_[idx]\n",
        "        w = self._weights_from_distances(dist)\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        if self.task == \"regression\":\n",
        "            yhat = np.sum(w * neigh_y, axis=1) / (np.sum(w, axis=1) + self.eps)\n",
        "            outputs.append(yhat)\n",
        "        else:\n",
        "            classes = np.unique(self.y_)\n",
        "            votes = np.zeros((idx.shape[0], classes.size), dtype=float)\n",
        "            for ci, c in enumerate(classes):\n",
        "                votes[:, ci] = np.sum(w * (neigh_y == c), axis=1)\n",
        "            proba = votes / (np.sum(votes, axis=1, keepdims=True) + self.eps)\n",
        "            yhat = classes[np.argmax(proba, axis=1)]\n",
        "            outputs.append(yhat)\n",
        "            if return_proba:\n",
        "                outputs.append(proba)\n",
        "\n",
        "        if explain:\n",
        "            Xq = np.asarray(X_query, dtype=float)\n",
        "            if Xq.ndim == 1:\n",
        "                Xq = Xq[None, :]\n",
        "            Xn = self.X_[idx]\n",
        "            diff = np.abs(Xn - Xq[:, None, :])\n",
        "            diff = np.where(np.isnan(diff), np.nan, diff)\n",
        "            feat_imp = np.nanmean(diff, axis=1)\n",
        "            outputs.append(feat_imp)\n",
        "\n",
        "        if return_neighbors:\n",
        "            outputs.append(idx)\n",
        "            outputs.append(dist)\n",
        "\n",
        "        return outputs[0] if len(outputs) == 1 else tuple(outputs)\n",
        "\n",
        "    def conformal_set(self, X_query, alpha=0.1):\n",
        "        yhat, proba = self.predict(X_query, return_proba=True)\n",
        "        classes = np.unique(self.y_)\n",
        "        sets = []\n",
        "        for i in range(proba.shape[0]):\n",
        "            sets.append(classes[proba[i] >= alpha])\n",
        "        return sets\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Metrics (NumPy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    return float(np.mean(y_true == y_pred))\n",
        "\n",
        "def confusion_matrix(y_true, y_pred, labels=None):\n",
        "    if labels is None:\n",
        "        labels = np.unique(np.concatenate([y_true, y_pred]))\n",
        "    labels = np.asarray(labels)\n",
        "    m = np.zeros((labels.size, labels.size), dtype=int)\n",
        "    for i, a in enumerate(labels):\n",
        "        for j, b in enumerate(labels):\n",
        "            m[i, j] = int(np.sum((y_true == a) & (y_pred == b)))\n",
        "    return labels, m\n",
        "\n",
        "def precision_recall_f1(y_true, y_pred, positive=1):\n",
        "    tp = np.sum((y_true == positive) & (y_pred == positive))\n",
        "    fp = np.sum((y_true != positive) & (y_pred == positive))\n",
        "    fn = np.sum((y_true == positive) & (y_pred != positive))\n",
        "    prec = tp / (tp + fp + 1e-12)\n",
        "    rec  = tp / (tp + fn + 1e-12)\n",
        "    f1   = 2 * prec * rec / (prec + rec + 1e-12)\n",
        "    return float(prec), float(rec), float(f1)\n",
        "\n",
        "def plot_confusion_matrix(cm, labels, title=\"Confusion matrix\"):\n",
        "    plt.figure(figsize=(4.5, 4))\n",
        "    plt.imshow(cm, interpolation=\"nearest\")\n",
        "    plt.title(title)\n",
        "    plt.xticks(np.arange(len(labels)), labels)\n",
        "    plt.yticks(np.arange(len(labels)), labels)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Train + test KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "nominal_idx = [2, 3]  # Shape, Margin (demo)\n",
        "\n",
        "knn = KNN(\n",
        "    k=11,\n",
        "    task=\"classification\",\n",
        "    p=2.0,\n",
        "    weights=\"distance\",\n",
        "    distance_power=2.0,\n",
        "    nominal_idx=nominal_idx,\n",
        "    missing=\"impute\",\n",
        "    learn_diagonal_metric=True\n",
        ").fit(X_train, y_train)\n",
        "\n",
        "y_pred, proba, feat_imp, neigh_idx, neigh_dist = knn.predict(\n",
        "    X_test, return_proba=True, explain=True, return_neighbors=True\n",
        ")\n",
        "\n",
        "acc = accuracy(y_test, y_pred)\n",
        "prec, rec, f1 = precision_recall_f1(y_test, y_pred, positive=1)\n",
        "acc, prec, rec, f1\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "labels, cm = confusion_matrix(y_test, y_pred, labels=np.array([0,1]))\n",
        "plot_confusion_matrix(cm, labels, title=\"Mammographic Mass: KNN confusion matrix\")\n",
        "cm\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Complex visualization: PCA (NumPy) + decision regions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def pca_fit(X, n_components=2):\n",
        "    mu = np.mean(X, axis=0, keepdims=True)\n",
        "    Xc = X - mu\n",
        "    C = (Xc.T @ Xc) / (Xc.shape[0] - 1)\n",
        "    eigvals, eigvecs = np.linalg.eigh(C)\n",
        "    order = np.argsort(eigvals)[::-1]\n",
        "    W = eigvecs[:, order[:n_components]]\n",
        "    return mu, W\n",
        "\n",
        "def pca_transform(X, mu, W):\n",
        "    return (X - mu) @ W\n",
        "\n",
        "mu_pca, W_pca = pca_fit(X_train, n_components=2)\n",
        "Z_train = pca_transform(X_train, mu_pca, W_pca)\n",
        "Z_test  = pca_transform(X_test,  mu_pca, W_pca)\n",
        "Z_train.shape\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "knn2d = KNN(k=21, task=\"classification\", weights=\"distance\", distance_power=2.0, missing=\"impute\").fit(Z_train, y_train)\n",
        "\n",
        "pad = 0.5\n",
        "x_min, x_max = Z_train[:, 0].min() - pad, Z_train[:, 0].max() + pad\n",
        "y_min, y_max = Z_train[:, 1].min() - pad, Z_train[:, 1].max() + pad\n",
        "\n",
        "grid_n = 250\n",
        "xs = np.linspace(x_min, x_max, grid_n)\n",
        "ys = np.linspace(y_min, y_max, grid_n)\n",
        "xx, yy = np.meshgrid(xs, ys)\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "grid_pred = knn2d.predict(grid).reshape(xx.shape)\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.contourf(xx, yy, grid_pred, alpha=0.35)\n",
        "plt.scatter(Z_test[:, 0], Z_test[:, 1], c=y_test, s=25)\n",
        "plt.title(\"Decision regions (PCA 2D) + test points\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) TensorFlow interoperability (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    import tensorflow as tf\n",
        "\n",
        "    @tf.function\n",
        "    def knn_predict_tf(x_batch):\n",
        "        y = tf.numpy_function(func=lambda a: knn.predict(a), inp=[x_batch], Tout=tf.int64)\n",
        "        y.set_shape([None])\n",
        "        return y\n",
        "\n",
        "    knn_predict_tf(tf.constant(X_test[:8], dtype=tf.float32)).numpy()\n",
        "except Exception as e:\n",
        "    print(\"TensorFlow not available here, but this wrapper pattern works in TF environments.\")\n",
        "    print(\"Error:\", e)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}